{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats classification using transfer learning and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel shows how to use transfer learning to classify dogs and cats images. If you find this kernel useful please upvote it!\n",
    "\n",
    "Transfer learning means that instead of your model learning everything from scratch, it uses another model that was trained on a similar problem, so that you can \"transfer\" the learned \"knowledge\" of the pretrained model to your model, and then learn some new features.\n",
    "\n",
    "The ImageNet Data set is huge data set consisting of more that 14 million images from more than 22,000 different categories, here we are using a smaller version of it which has 1000 different categories.\n",
    "\n",
    "In this kernel we use an xception model which is pretrained on the ImageNet dataset and then build some layers on top of it to be able to classify dogs and cats images.\n",
    "\n",
    "Transfer learning makes sense here because the ImageNet data set has a much larger number of images (14 million) than the dog-cat data set (25,000). This increases the speed of training of our model and the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-22T19:24:05.501166Z",
     "iopub.status.busy": "2025-04-22T19:24:05.500777Z",
     "iopub.status.idle": "2025-04-22T19:24:05.513041Z",
     "shell.execute_reply": "2025-04-22T19:24:05.511460Z",
     "shell.execute_reply.started": "2025-04-22T19:24:05.501132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras.applications.xception as xception\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print('setup successful!')\n",
    "print(f'keras version {keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-04-22T19:24:05.516705Z",
     "iopub.status.busy": "2025-04-22T19:24:05.516284Z",
     "iopub.status.idle": "2025-04-22T19:24:05.534152Z",
     "shell.execute_reply": "2025-04-22T19:24:05.531980Z",
     "shell.execute_reply.started": "2025-04-22T19:24:05.516633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# The image net have 1000 categories, and so 1000 outputs, so we get 1000 different features\n",
    "IMAGE_FEATURES_SIZE = 1000\n",
    "\n",
    "# For the first run PERFORM_UNZIPPING must be True, but after the first run,\n",
    "# it can be set to False skip the unzipping step to save time\n",
    "PERFORM_UNZIPPING = True\n",
    "\n",
    "print('defining constants successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip the Train and Test folders\n",
    "\n",
    "The train and test folders are zipped, the code below unzips both folders and the unzipped folders are saved in the output folder. For the First run PERFORM_UNZIPPING should be true to perform the unzipping, later if the folders are already unzipped you can change it to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T19:24:05.536894Z",
     "iopub.status.busy": "2025-04-22T19:24:05.536428Z",
     "iopub.status.idle": "2025-04-22T19:24:05.556477Z",
     "shell.execute_reply": "2025-04-22T19:24:05.554870Z",
     "shell.execute_reply.started": "2025-04-22T19:24:05.536855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if PERFORM_UNZIPPING == False:\n",
    "    # Unzip the input folders\n",
    "    with zipfile.ZipFile(\"../input/lion-data/trainlion/train\", \"r\") as z:\n",
    "        z.extractall(\".\")\n",
    "\n",
    "    with zipfile.ZipFile(\"../input/lion-data/testlion/test\", \"r\") as z:\n",
    "        z.extractall(\".\")\n",
    "\n",
    "    print('Unzipping done!')\n",
    "\n",
    "else:\n",
    "    print('Unzipping not needed')\n",
    "\n",
    "imgs_path = \"/kaggle/input/training-data-with-redondo/trainlion_redondo/trainlion_redondo/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare load_image function and Data Frame\n",
    "The pretrained model that we are using here is the xception model. The advantage of the xception model is that it has a small size, relatively small number of parameters and high accuracy. You can have a look with on a comparison of different pretrained models available in Keras in https://keras.io/api/applications/\n",
    "\n",
    "\n",
    "The function 'load_image' takes the path of an image as an input and return the preprocessed image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T19:24:05.559009Z",
     "iopub.status.busy": "2025-04-22T19:24:05.558517Z",
     "iopub.status.idle": "2025-04-22T19:24:05.577254Z",
     "shell.execute_reply": "2025-04-22T19:24:05.575528Z",
     "shell.execute_reply.started": "2025-04-22T19:24:05.558959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _load_image(img_path):\n",
    "    # load the image from the directory\n",
    "    img = image.load_img(img_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img = image.img_to_array(img)\n",
    "    # add an additional dimension, (i.e. change the shape of each image from (224, 224, 3) to (1, 224, 224, 3)\n",
    "    # This shape is suitable for training\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    # Apply preprocessing for the image, so that the training is faster\n",
    "    img = xception.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a  dataframe that contains a list of the file names and the corresponding category. Category 1 means lion, 0 means no lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T19:24:05.579602Z",
     "iopub.status.busy": "2025-04-22T19:24:05.579203Z",
     "iopub.status.idle": "2025-04-22T19:24:05.625008Z",
     "shell.execute_reply": "2025-04-22T19:24:05.620743Z",
     "shell.execute_reply.started": "2025-04-22T19:24:05.579566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filenames = os.listdir(imgs_path)\n",
    "\n",
    "categories = []\n",
    "\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'lion':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print('number of elements = ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.626085Z",
     "iopub.status.idle": "2025-04-22T19:24:05.626546Z",
     "shell.execute_reply": "2025-04-22T19:24:05.626318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# see sample image, you can run the same cell again to get a different image\n",
    "sample = random.choice(filenames)\n",
    "randomimage = image.load_img(imgs_path + sample)\n",
    "plt.imshow(randomimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Pretrained Model\n",
    "There are two approaches for transfer learning:\n",
    "1. One model where the first part of it is the pretrained model and the second part is your new model. \n",
    "1. Pass all the images through the pretrained model, to get the extracted features and then use those extrated features to    train your new model. \n",
    "\n",
    "Here we will use the second approach (the feature extraction approach), because a matrix which contains all our images with the shape (224, 224, 3) will not fit in our RAM. So we first pass all the images through the xception model and get the extracted features, as mentioned above the model has 1000 categories, so the output will have a size of 1000 which is much smaller than (224 X 224 X 3 = 150,528) . So if we have 100 images the training matrix will have a shape of (100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.628136Z",
     "iopub.status.idle": "2025-04-22T19:24:05.628589Z",
     "shell.execute_reply": "2025-04-22T19:24:05.628370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create the xception model used for the feature extraction\n",
    "model_xception = xception.Xception(\n",
    "    include_top=True, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "    weights='../input/xception/xception_weights_tf_dim_ordering_tf_kernels.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the EarlyStopping call back to stop our training  if the accuracy is not improving for a certain number of epochs. \n",
    "If the accuracy is not improving for a certain number of epochs then it makes sense to reduce the learning rate, we implement that using the ReduceLROnPlateau call back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.629964Z",
     "iopub.status.idle": "2025-04-22T19:24:05.630404Z",
     "shell.execute_reply": "2025-04-22T19:24:05.630184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define call backs\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(patience=7, verbose=1)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(patience=3, verbose=1, factor=0.5)\n",
    "\n",
    "print('call backs defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "The extract_features function will take the pretrained model used for feature extraction and a batch of images, then it will pass those images through the model to obtain the extracted features. It is better to pass a maximum of a round 1000 images at a time in order not to fill our RAM. The data_set parameter is dataframe containing filenames and the corresponding categories for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.631321Z",
     "iopub.status.idle": "2025-04-22T19:24:05.631796Z",
     "shell.execute_reply": "2025-04-22T19:24:05.631537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ImageDataGenerator instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.633062Z",
     "iopub.status.idle": "2025-04-22T19:24:05.633486Z",
     "shell.execute_reply": "2025-04-22T19:24:05.633275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    # featurewise_center=True,\n",
    "    # featurewise_std_normalization=True,\n",
    "    # rotation_range=10,\n",
    "    # width_shift_range=0.2,\n",
    "    # height_shift_range=0.2,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    # fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]  # Adjust brightness between 80% and 120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify extract_features function for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.634355Z",
     "iopub.status.idle": "2025-04-22T19:24:05.634842Z",
     "shell.execute_reply": "2025-04-22T19:24:05.634553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PERFORM_AUGMENTATION = True  # Set to False to disable augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.636198Z",
     "iopub.status.idle": "2025-04-22T19:24:05.636625Z",
     "shell.execute_reply": "2025-04-22T19:24:05.636418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_features(model, data_set, augment=PERFORM_AUGMENTATION):\n",
    "    features = []\n",
    "    all_images = []\n",
    "\n",
    "    print(f'data set has {len(data_set)} entries')\n",
    "    for data_set_entry in data_set:\n",
    "        file_name = data_set_entry[0]\n",
    "        category = data_set_entry[1]\n",
    "        path = imgs_path + file_name\n",
    "        img = image.load_img(path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        x = image.img_to_array(img)\n",
    "        all_images.append(x)\n",
    "\n",
    "    # Get mean and standard deviation for normalization.\n",
    "    print(f'shape of an image: {all_images[0].shape}')\n",
    "    all_images_combined = np.array(all_images)\n",
    "    mean = np.mean(all_images_combined, axis=(0, 1, 2))\n",
    "    std = np.std(all_images_combined, axis=(0, 1, 2))\n",
    "\n",
    "    for x in all_images:\n",
    "        x = (x - mean) / std\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        if augment:\n",
    "            # Apply augmentation\n",
    "            aug_iter = datagen.flow(x, batch_size=1)\n",
    "            aug_img = next(aug_iter)[0]\n",
    "\n",
    "            aug_img = xception.preprocess_input(aug_img)\n",
    "            # extract features\n",
    "            pred = model.predict(np.expand_dims(aug_img, axis=0))\n",
    "            features.append(pred)\n",
    "        else:\n",
    "            # Use original image\n",
    "            x = xception.preprocess_input(x)\n",
    "            pred = model.predict(x)\n",
    "            features.append(pred)\n",
    "\n",
    "    return np.array(features).reshape(len(data_set), IMAGE_FEATURES_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the training set into three separate sets:\n",
    "1. **The training set**: used to train our model.\n",
    "2. **The validation set**: used to double check that our model is not overfitting the training set, i.e. it can also generalise    to other data other than the train data\n",
    "3. **The test set**: Used to estimate the accuracy of the model on new data other than the ones the model used for training\n",
    "\n",
    "For a competetion or for some other cases, you can split the data only to training and validation sets inorder to acheive te highest possible accuracy, without the need to properly estimate how accurate the model really is.\n",
    "\n",
    "We split the data set as follows: 2% test set, 82% train set, 16% cross_validation set\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.637787Z",
     "iopub.status.idle": "2025-04-22T19:24:05.638268Z",
     "shell.execute_reply": "2025-04-22T19:24:05.638022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set, validate_set, test_set = np.split(\n",
    "    df.sample(frac=1, random_state=43), [int(.82*len(df)), int(.96*len(df))])\n",
    "\n",
    "# Visualize the data distribution\n",
    "fig, axis = plt.subplots(1, 3)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(80, 20)\n",
    "\n",
    "ax0 = sns.countplot(data=train_set, x='category', ax=axis[0])\n",
    "ax1 = sns.countplot(data=validate_set, x='category', ax=axis[1])\n",
    "ax2 = sns.countplot(data=test_set, x='category', ax=axis[2])\n",
    "\n",
    "ax0.set_title('train data', fontsize=60)\n",
    "ax1.set_title('cross validation data', fontsize=60)\n",
    "ax2.set_title('test data', fontsize=60)\n",
    "\n",
    "ax0.tick_params(labelsize=55)\n",
    "ax1.tick_params(labelsize=55)\n",
    "ax2.tick_params(labelsize=55)\n",
    "\n",
    "print('shape of train_set:   ', np.shape(train_set))\n",
    "print('shape of validate_set:', np.shape(validate_set))\n",
    "print('shape of test_set:    ', np.shape(test_set))\n",
    "\n",
    "# convert the dataframes to numpy matrices\n",
    "train_set = train_set.to_numpy()\n",
    "validate_set = validate_set.to_numpy()\n",
    "test_set = test_set.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the feature extraction. We take chunks of the train_set (1000 at a time) and pass them through the pretrained model, and save the extracted features in train_x. We then do the same with the validation_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.639367Z",
     "iopub.status.idle": "2025-04-22T19:24:05.639876Z",
     "shell.execute_reply": "2025-04-22T19:24:05.639589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "# prepare parameters for model.fit\n",
    "train_x = np.zeros((len(train_set), 1000))\n",
    "train_y = np.zeros((len(train_set)))\n",
    "\n",
    "validate_x = np.zeros((len(validate_set), 1000))\n",
    "validate_y = np.zeros((len(validate_set)))\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "# extract features from train_set nd save it into train_x\n",
    "for i, train_set_chunk in enumerate(chunks(train_set, chunk_size)):\n",
    "    train_x[(i*chunk_size): (i*chunk_size + chunk_size)\n",
    "            ] = extract_features(model_xception, train_set_chunk)\n",
    "\n",
    "print('shape of train_x: ', np.shape(train_x))\n",
    "\n",
    "# extract features from validate_set nd save it into validate_x\n",
    "for i, validate_set_chunk in enumerate(chunks(validate_set, chunk_size)):\n",
    "    validate_x[(i*chunk_size): (i*chunk_size + chunk_size)\n",
    "               ] = extract_features(model_xception, validate_set_chunk)\n",
    "\n",
    "print('shape of validate_x: ', np.shape(validate_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the second column from the train_set (the category column) and save it in train_y. We then convert it to a one-hot vector using the \"to_categorically\" method, we need the one-hot format for the model fitting later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.641023Z",
     "iopub.status.idle": "2025-04-22T19:24:05.641485Z",
     "shell.execute_reply": "2025-04-22T19:24:05.641243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# prepare train_y\n",
    "train_y = train_set[:, 1]\n",
    "train_y = to_categorical(train_y)\n",
    "\n",
    "# prepare validate_y\n",
    "validate_y = validate_set[:, 1]\n",
    "validate_y = to_categorical(validate_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the new model and train it\n",
    "Note that it is a small model, that is because it doesn't need to learn everything from scratch because we are using the extracted features. Also learning will take just around 30 seconds using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.642588Z",
     "iopub.status.idle": "2025-04-22T19:24:05.643109Z",
     "shell.execute_reply": "2025-04-22T19:24:05.642864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "APPLY_REGULARIZATION = True  # Set to False to disable regularization\n",
    "\n",
    "transfer_model = keras.Sequential()\n",
    "\n",
    "transfer_model.add(keras.Input(shape=(IMAGE_FEATURES_SIZE)))\n",
    "transfer_model.add(layers.Flatten())\n",
    "\n",
    "if APPLY_REGULARIZATION:\n",
    "    transfer_model.add(\n",
    "        layers.Dense(100, activation='relu',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "    transfer_model.add(\n",
    "        layers.Dense(16, activation='relu',\n",
    "                     kernel_regularizer=keras.regularizers.l1(0.001)))\n",
    "else:\n",
    "    transfer_model.add(\n",
    "        layers.Dense(100, activation='relu')\n",
    "    )\n",
    "    transfer_model.add(\n",
    "        layers.Dense(16, activation='relu')\n",
    "    )\n",
    "\n",
    "transfer_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.644094Z",
     "iopub.status.idle": "2025-04-22T19:24:05.644549Z",
     "shell.execute_reply": "2025-04-22T19:24:05.644310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# compile and fit the model\n",
    "transfer_model.compile(loss='binary_crossentropy',\n",
    "                       optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "history = transfer_model.fit(x=train_x, y=train_y, batch_size=16, epochs=EPOCHS,\n",
    "                             callbacks=[early_stop, learning_rate_reduction],\n",
    "                             validation_data=(validate_x, validate_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.645606Z",
     "iopub.status.idle": "2025-04-22T19:24:05.646106Z",
     "shell.execute_reply": "2025-04-22T19:24:05.645868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transfer_model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.647152Z",
     "iopub.status.idle": "2025-04-22T19:24:05.647619Z",
     "shell.execute_reply": "2025-04-22T19:24:05.647379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "ax1.set_yticks(np.arange(0, 0.14, 0.02))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'],\n",
    "         color='r', label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "ax2.legend()\n",
    "\n",
    "legend = plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "Predict the class for the test set and evaluate the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.648690Z",
     "iopub.status.idle": "2025-04-22T19:24:05.649173Z",
     "shell.execute_reply": "2025-04-22T19:24:05.648916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_x = np.zeros((len(test_set), 1000))\n",
    "test_y = np.zeros((len(test_set)))\n",
    "\n",
    "# extract features from test_set and save it into test_x\n",
    "for i, test_set_chunk in enumerate(chunks(test_set, chunk_size)):\n",
    "    test_x[(i*chunk_size): (i*chunk_size + chunk_size)\n",
    "           ] = extract_features(model_xception, test_set_chunk)\n",
    "\n",
    "# prepare test_y\n",
    "test_y = test_set[:, 1]\n",
    "test_y = to_categorical(test_y)\n",
    "\n",
    "assert (np.shape(test_y) == (np.shape(test_set)[0], 2))\n",
    "\n",
    "# predict and estimate the accuracy\n",
    "_, accuracy = transfer_model.evaluate(test_x, test_y)\n",
    "print('accuracy on test set = ',  round((accuracy * 100), 2), '% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Class of Random Image\n",
    "The cell below will randomly select an image from the test set, predict if it is a dog or cat. You can run the cell several times to get different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.650118Z",
     "iopub.status.idle": "2025-04-22T19:24:05.650565Z",
     "shell.execute_reply": "2025-04-22T19:24:05.650334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_string_in_filename(filepath, search_string):\n",
    "    \"\"\"\n",
    "    Checks if a specified string is present in a filename.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the file.\n",
    "        search_string: The string to search for within the filename.\n",
    "\n",
    "    Returns:\n",
    "        True if the string is found in the filename, False otherwise.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    return search_string in filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.651870Z",
     "iopub.status.idle": "2025-04-22T19:24:05.652326Z",
     "shell.execute_reply": "2025-04-22T19:24:05.652094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = random.choice(test_set)[0]\n",
    "randomimage = image.load_img(imgs_path + sample)\n",
    "plt.imshow(randomimage)\n",
    "\n",
    "loaded_image = _load_image(imgs_path + sample)\n",
    "extracted_feat = model_xception.predict(loaded_image)\n",
    "pred = transfer_model.predict(extracted_feat)\n",
    "\n",
    "pred = pred[0]  # convert to array\n",
    "if pred[0] >= pred[1]:\n",
    "    prediction_class = 'no lion'\n",
    "    prediction_percentage = pred[0]\n",
    "    string_to_find = \"other\"\n",
    "    if check_string_in_filename(sample, string_to_find):\n",
    "        print('CORRECT')\n",
    "    else:\n",
    "        print('FALSE NEGATIVE')\n",
    "else:\n",
    "    prediction_class = 'lion'\n",
    "    prediction_percentage = pred[1]\n",
    "    string_to_find = \"lion\"\n",
    "    if check_string_in_filename(sample, string_to_find):\n",
    "        print('CORRECT')\n",
    "    else:\n",
    "        print('FALSE POSITIVE')\n",
    "\n",
    "print(sample)\n",
    "print('I am ', int(prediction_percentage*100),\n",
    "      '% sure that I am a ', prediction_class, '!', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run on Real Test Images**\n",
    "Specify your own directory of lion and other animal images in the realtestimgs_path to test the model on images with backgrounds not in the training, validation and test sets above. Note the test set above is simply split out from the training and validation sets so backgrounds and animals will be similar. This test allows to really test the generalization of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.653284Z",
     "iopub.status.idle": "2025-04-22T19:24:05.653751Z",
     "shell.execute_reply": "2025-04-22T19:24:05.653495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "realtestimgs_path = \"/kaggle/input/testsnow01/testsnow01/\"\n",
    "\n",
    "\n",
    "def _load_image(realtestimgs_path):\n",
    "    img_real = image.load_img(realtestimgs_path, target_size=(\n",
    "        IMAGE_WIDTH, IMAGE_HEIGHT))  # load the image from the directory\n",
    "    img_real = image.img_to_array(img_real)\n",
    "    # add an additional dimension, (i.e. change the shape of each image from (224, 224, 3) to (1, 224, 224, 3)\n",
    "    # This shape is suitable for training\n",
    "    img_real = np.expand_dims(img_real, axis=0)\n",
    "    # Apply preprocessing for the image, so that the training is faster\n",
    "    img_real = xception.preprocess_input(img_real)\n",
    "\n",
    "    return img_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.654793Z",
     "iopub.status.idle": "2025-04-22T19:24:05.655246Z",
     "shell.execute_reply": "2025-04-22T19:24:05.655016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filenames = os.listdir(realtestimgs_path)\n",
    "\n",
    "categories = []\n",
    "\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'lion':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print('number of elements = ', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "transfer_model = keras.Sequential()\n",
    "\n",
    "transfer_model.add(keras.Input(shape = (IMAGE_FEATURES_SIZE)))\n",
    "transfer_model.add(layers.Flatten())\n",
    "transfer_model.add(layers.Dense(100, activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.01)))  # L2 regularization\n",
    "transfer_model.add(layers.Dense(16,  activation = 'relu', kernel_regularizer=keras.regularizers.l1(0.001))) # L1 regularization\n",
    "transfer_model.add(layers.Dense(2,   activation = 'softmax'))That's it, if you find this kernel useful please upvote it :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.656281Z",
     "iopub.status.idle": "2025-04-22T19:24:05.656754Z",
     "shell.execute_reply": "2025-04-22T19:24:05.656490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "real_test_set = df.to_numpy()\n",
    "\n",
    "\n",
    "def copy_file_to_directory(source_path, destination_directory):\n",
    "    \"\"\"\n",
    "    Copies a file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        source_path (str): The path to the file to be copied.\n",
    "        destination_directory (str): The path to the directory where the file should be copied.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the destination directory exists; create it if not\n",
    "        os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "        # Copy the file to the destination directory\n",
    "        shutil.copy2(source_path, destination_directory)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{source_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-22T19:24:05.657761Z",
     "iopub.status.idle": "2025-04-22T19:24:05.658202Z",
     "shell.execute_reply": "2025-04-22T19:24:05.657973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "failedimages_path = \"/kaggle/working/failedcases/\"\n",
    "sortfilenames = sorted(filenames)\n",
    "error_count = 0\n",
    "image_count = 0\n",
    "for filename in sortfilenames:\n",
    "    sample = random.choice(real_test_set)[0]\n",
    "    randomimage = image.load_img(realtestimgs_path + filename)\n",
    "    plt.imshow(randomimage)\n",
    "    plt.show(randomimage)\n",
    "\n",
    "    loaded_image = _load_image(realtestimgs_path + filename)\n",
    "    extracted_feat = model_xception.predict(loaded_image)\n",
    "    pred = transfer_model.predict(extracted_feat)\n",
    "    image_count = image_count + 1\n",
    "    pred = pred[0]  # convert to array\n",
    "    if pred[0] >= pred[1]:\n",
    "        prediction_class = 'no lion'\n",
    "        prediction_percentage = pred[0]\n",
    "        string_to_find = \"other\"\n",
    "        if check_string_in_filename(filename, string_to_find):\n",
    "            print('CORRECT')\n",
    "        else:\n",
    "            print('FALSE NEGATIVE')\n",
    "            copy_file_to_directory(\n",
    "                realtestimgs_path + filename, failedimages_path)\n",
    "            error_count = error_count + 1\n",
    "    else:\n",
    "        prediction_class = 'lion'\n",
    "        prediction_percentage = pred[1]\n",
    "        string_to_find = \"lion\"\n",
    "        if check_string_in_filename(filename, string_to_find):\n",
    "            print('CORRECT')\n",
    "        else:\n",
    "            print('FALSE POSITIVE')\n",
    "            copy_file_to_directory(\n",
    "                realtestimgs_path + filename, failedimages_path)\n",
    "            error_count = error_count + 1\n",
    "\n",
    "    print(filename)\n",
    "    print('I am ', int(prediction_percentage*100),\n",
    "          '% sure that I am a ', prediction_class, '!', sep='')\n",
    "    print('-------------------------------------------------------------------')\n",
    "print('Total Images =', image_count, 'Incorrect Images =',\n",
    "      error_count, 'Accuracy =', (1-(error_count/image_count))*100)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 38425,
     "isSourceIdPinned": false,
     "sourceId": 5441,
     "sourceType": "competition"
    },
    {
     "datasetId": 6300,
     "sourceId": 9905,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6924616,
     "isSourceIdPinned": true,
     "sourceId": 11107803,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6927123,
     "sourceId": 11110879,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6927448,
     "sourceId": 11111333,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30042,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pumaguard-xkhQR0xi-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
